{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "58b4f227-ae9a-4707-b008-23a3b40a6b8a",
      "metadata": {
        "id": "58b4f227-ae9a-4707-b008-23a3b40a6b8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as ss\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0ebfde05-4322-4317-afd8-a1998dfbddb9",
      "metadata": {
        "id": "0ebfde05-4322-4317-afd8-a1998dfbddb9"
      },
      "outputs": [],
      "source": [
        "def PCA(X , num_components):\n",
        "     \n",
        "    #Step-1\n",
        "    X_meaned = X - np.mean(X , axis = 0)\n",
        "     \n",
        "    #Step-2\n",
        "    cov_mat = np.cov(X_meaned , rowvar = False)\n",
        "     \n",
        "    #Step-3\n",
        "    eigen_values , eigen_vectors = np.linalg.eigh(cov_mat)\n",
        "     \n",
        "    #Step-4\n",
        "    sorted_index = np.argsort(eigen_values)[::-1]\n",
        "    sorted_eigenvalue = eigen_values[sorted_index]\n",
        "    sorted_eigenvectors = eigen_vectors[:,sorted_index]\n",
        "     \n",
        "    #Step-5\n",
        "    eigenvector_subset = sorted_eigenvectors[:,0:num_components]\n",
        "     \n",
        "    #Step-6\n",
        "    X_reduced = np.dot(eigenvector_subset.transpose() , X_meaned.transpose() ).transpose()\n",
        "     \n",
        "    return X_reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "11de344b-e638-4b98-a293-1e0dbd798483",
      "metadata": {
        "id": "11de344b-e638-4b98-a293-1e0dbd798483"
      },
      "outputs": [],
      "source": [
        "class Logistic_Regression:\n",
        "    \n",
        "    def __init__(self, X, y, learningRate = 0.00001, tolerance = 0.00005,maxIteration = 5000 ):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "        self.tolerance = tolerance\n",
        "        self.maxIteration = maxIteration\n",
        "        self.learningRate = learningRate\n",
        "    \n",
        "    def addX0(self):\n",
        "        return np.column_stack([np.ones([X.shape[0],1]), X])\n",
        "    \n",
        "    def sigmoid(self, z):\n",
        "        sig= 1 / (1+ np.exp(-z))\n",
        "        return sig\n",
        "    \n",
        "    def costFunction (self, X, y):\n",
        "        pred_ = np.log(np.ones(X.shape[0]) + np.exp(X.dot(self.w))) - X.dot(self.w).dot(y)\n",
        "        cost = pred_.sum()\n",
        "        return cost\n",
        "    \n",
        "    def gradient(self, X, y):\n",
        "        sigmoid = self.sigmoid(X.dot(self.w))\n",
        "        grad = (sigmoid - y).dot(X)\n",
        "        return grad\n",
        "    \n",
        "    def gradientDescent(self, X, y):\n",
        "        \n",
        "        errors= []\n",
        "        last = float('inf')\n",
        "        \n",
        "        for i in tqdm(range(self.maxIteration)):\n",
        "            self.w = self.w - self.learningRate * self.gradient(X, y)\n",
        "            curr = self.costFunction(X, y)\n",
        "            \n",
        "            diff = last - curr\n",
        "            last = curr\n",
        "            \n",
        "            errors.append(curr)\n",
        "            \n",
        "        \n",
        "    def predict(self, X):\n",
        "        pred = self.sigmoid(X.dot(self.w))\n",
        "        return np.around(pred)\n",
        "        \n",
        "    def evaluate(self, y, y_hat):\n",
        "            \n",
        "        y = (y == 1)\n",
        "        y_hat= (y_hat == 1)\n",
        "            \n",
        "        accuracy = (y == y_hat).sum() / y.size\n",
        "        precision = (y & y_hat).sum() / y_hat.sum()\n",
        "        recall = (y & y_hat).sum() / y.sum()\n",
        "        #print('accuracy was:' +str(accuracy) )\n",
        "        #print('precision was:' +str(precision) )\n",
        "        #print('recall was:' +str(recall) )\n",
        "        return recall, precision, accuracy\n",
        "        \n",
        "    def fit(self):\n",
        "            \n",
        "        self.w = np.ones(self.X_train.shape[1], dtype = np.float64) * 0\n",
        "        self.gradientDescent(self.X_train, self.y_train)\n",
        "            \n",
        "            \n",
        "        y_hat_train = self.predict(self.X_train)\n",
        "        recall, precision, accuracy = self.evaluate(self.y_train, y_hat_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "92ae5101-c407-4b4f-969a-69f2804ff081",
      "metadata": {
        "id": "92ae5101-c407-4b4f-969a-69f2804ff081"
      },
      "outputs": [],
      "source": [
        "def NN (X_train,y_train,X_test,y_test,input_shape):\n",
        "    model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(input_shape,)),\n",
        "    #keras.layers.Dense(264, activation=tf.nn.relu),\n",
        "    #keras.layers.Dense(132, activation=tf.nn.relu),\n",
        "    #keras.layers.Dense(264, activation=tf.nn.relu),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy','AUC','mse'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=10)\n",
        "\n",
        "    test_loss, test_acc, auc, rmse = model.evaluate(X_test, y_test)\n",
        "    print('Test accuracy:', test_acc)\n",
        "    print('AUC:', auc)\n",
        "    \n",
        "    \n",
        "    pred=model.predict(X_test)\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(0,len(pred)):\n",
        "        if(pred[i]>0.5):\n",
        "            pred[i]=1\n",
        "        else:\n",
        "            pred[i]=0\n",
        "    cm=confusion_matrix(y_test, pred)\n",
        "    print('Precision: '+str(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "    print('Recall: '+str(cm[1][1]/(cm[1][1]+cm[1][0])))\n",
        "    \n",
        "    \n",
        "  \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8c9fe2e3-b3a1-4ff7-88d4-caba28282efd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c9fe2e3-b3a1-4ff7-88d4-caba28282efd",
        "outputId": "10e4a924-0a6e-4098-9f67-f3342b5db417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XXXXXXXXXXXXX\n",
            "DATASET: 1\n",
            "XXXXXXXXXXXXX\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "--------NEURAL NETWORK------------\n",
            "----------------------------------\n",
            " \n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141/141 [==============================] - 1s 2ms/step - loss: 0.7072 - accuracy: 0.5596 - auc: 0.6001 - mse: 0.2517\n",
            "Epoch 2/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6539 - auc: 0.7285 - mse: 0.2108\n",
            "Epoch 3/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7064 - auc: 0.7945 - mse: 0.1866\n",
            "Epoch 4/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7830 - auc: 0.8543 - mse: 0.1565\n",
            "Epoch 5/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7965 - auc: 0.8733 - mse: 0.1462\n",
            "Epoch 6/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8270 - auc: 0.9018 - mse: 0.1252\n",
            "Epoch 7/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8525 - auc: 0.9083 - mse: 0.1170\n",
            "Epoch 8/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8730 - auc: 0.9369 - mse: 0.0961\n",
            "Epoch 9/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8851 - auc: 0.9393 - mse: 0.0925\n",
            "Epoch 10/10\n",
            "141/141 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8908 - auc: 0.9466 - mse: 0.0849\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 1.2292 - accuracy: 0.6354 - auc: 0.7431 - mse: 0.2854\n",
            "Test accuracy: 0.635371208190918\n",
            "AUC: 0.7431184649467468\n",
            "Precision: 0.7540983606557377\n",
            "Recall: 0.4017467248908297\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "-------LOGISTIC REGRESSION--------\n",
            "----------------------------------\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:01<00:00, 3296.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6451965065502183\n",
            "Precision: 0.6423982869379015\n",
            "Recall: 0.6550218340611353\n",
            "\n",
            "\n",
            "\n",
            "XXXXXXXXXXXXX\n",
            "DATASET: 2\n",
            "XXXXXXXXXXXXX\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "--------NEURAL NETWORK------------\n",
            "----------------------------------\n",
            " \n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.5781 - auc: 0.6252 - mse: 0.2456\n",
            "Epoch 2/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6916 - auc: 0.7645 - mse: 0.1982\n",
            "Epoch 3/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7520 - auc: 0.8280 - mse: 0.1695\n",
            "Epoch 4/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7996 - auc: 0.8702 - mse: 0.1448\n",
            "Epoch 5/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8355 - auc: 0.9045 - mse: 0.1229\n",
            "Epoch 6/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8610 - auc: 0.9284 - mse: 0.1048\n",
            "Epoch 7/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.3007 - accuracy: 0.8792 - auc: 0.9376 - mse: 0.0926\n",
            "Epoch 8/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9018 - auc: 0.9545 - mse: 0.0777\n",
            "Epoch 9/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.9121 - auc: 0.9595 - mse: 0.0733\n",
            "Epoch 10/10\n",
            "204/204 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9190 - auc: 0.9669 - mse: 0.0628\n",
            "43/43 [==============================] - 0s 2ms/step - loss: 1.9907 - accuracy: 0.5368 - auc: 0.5869 - mse: 0.3914\n",
            "Test accuracy: 0.5368188619613647\n",
            "AUC: 0.5868837833404541\n",
            "Precision: 0.625\n",
            "Recall: 0.18409425625920472\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "-------LOGISTIC REGRESSION--------\n",
            "----------------------------------\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:02<00:00, 2443.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5589101620029455\n",
            "Precision: 0.5533333333333333\n",
            "Recall: 0.6111929307805597\n",
            "\n",
            "\n",
            "\n",
            "XXXXXXXXXXXXX\n",
            "DATASET: 3\n",
            "XXXXXXXXXXXXX\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "--------NEURAL NETWORK------------\n",
            "----------------------------------\n",
            " \n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211/211 [==============================] - 1s 2ms/step - loss: 0.6661 - accuracy: 0.6256 - auc: 0.6683 - mse: 0.2339\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7299 - auc: 0.7939 - mse: 0.1866\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7744 - auc: 0.8546 - mse: 0.1561\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.8005 - auc: 0.8823 - mse: 0.1383\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8346 - auc: 0.9099 - mse: 0.1200\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8649 - auc: 0.9313 - mse: 0.1024\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8891 - auc: 0.9435 - mse: 0.0896\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8986 - auc: 0.9500 - mse: 0.0817\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.9038 - auc: 0.9541 - mse: 0.0779\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.9175 - auc: 0.9632 - mse: 0.0668\n",
            "44/44 [==============================] - 0s 2ms/step - loss: 1.1889 - accuracy: 0.6284 - auc: 0.7224 - mse: 0.2985\n",
            "Test accuracy: 0.628387987613678\n",
            "AUC: 0.7223835587501526\n",
            "Precision: 0.7284263959390863\n",
            "Recall: 0.4094151212553495\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "-------LOGISTIC REGRESSION--------\n",
            "----------------------------------\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:02<00:00, 2277.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.5970042796005706\n",
            "Precision: 0.5901856763925729\n",
            "Recall: 0.6348074179743224\n",
            "\n",
            "\n",
            "\n",
            "XXXXXXXXXXXXX\n",
            "DATASET: 4\n",
            "XXXXXXXXXXXXX\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "--------NEURAL NETWORK------------\n",
            "----------------------------------\n",
            " \n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198/198 [==============================] - 1s 2ms/step - loss: 0.7099 - accuracy: 0.5831 - auc: 0.6363 - mse: 0.2480\n",
            "Epoch 2/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6768 - auc: 0.7476 - mse: 0.2039\n",
            "Epoch 3/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7143 - auc: 0.7957 - mse: 0.1853\n",
            "Epoch 4/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7472 - auc: 0.8172 - mse: 0.1754\n",
            "Epoch 5/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7700 - auc: 0.8542 - mse: 0.1569\n",
            "Epoch 6/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7867 - auc: 0.8653 - mse: 0.1494\n",
            "Epoch 7/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8085 - auc: 0.8895 - mse: 0.1363\n",
            "Epoch 8/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8313 - auc: 0.9033 - mse: 0.1253\n",
            "Epoch 9/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8495 - auc: 0.9178 - mse: 0.1137\n",
            "Epoch 10/10\n",
            "198/198 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8587 - auc: 0.9286 - mse: 0.1051\n",
            "42/42 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.6468 - auc: 0.7793 - mse: 0.2412\n",
            "Test accuracy: 0.6468373537063599\n",
            "AUC: 0.7793164253234863\n",
            "Precision: 0.7656675749318801\n",
            "Recall: 0.42319277108433734\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "-------LOGISTIC REGRESSION--------\n",
            "----------------------------------\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:01<00:00, 2508.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7010542168674698\n",
            "Precision: 0.6811397557666214\n",
            "Recall: 0.7560240963855421\n",
            "\n",
            "\n",
            "\n",
            "XXXXXXXXXXXXX\n",
            "DATASET: 5\n",
            "XXXXXXXXXXXXX\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "--------NEURAL NETWORK------------\n",
            "----------------------------------\n",
            " \n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/115 [==============================] - 1s 2ms/step - loss: 0.7213 - accuracy: 0.5723 - auc: 0.6015 - mse: 0.2570\n",
            "Epoch 2/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6611 - auc: 0.7285 - mse: 0.2105\n",
            "Epoch 3/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7230 - auc: 0.8136 - mse: 0.1781\n",
            "Epoch 4/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7605 - auc: 0.8299 - mse: 0.1689\n",
            "Epoch 5/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7761 - auc: 0.8644 - mse: 0.1511\n",
            "Epoch 6/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7944 - auc: 0.8822 - mse: 0.1394\n",
            "Epoch 7/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8293 - auc: 0.9079 - mse: 0.1238\n",
            "Epoch 8/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8354 - auc: 0.9152 - mse: 0.1173\n",
            "Epoch 9/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8502 - auc: 0.9231 - mse: 0.1126\n",
            "Epoch 10/10\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8615 - auc: 0.9351 - mse: 0.1007\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.7252 - auc: 0.7921 - mse: 0.2023\n",
            "Test accuracy: 0.7251908183097839\n",
            "AUC: 0.7920770049095154\n",
            "Precision: 0.7940199335548173\n",
            "Recall: 0.6081424936386769\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------\n",
            "-------LOGISTIC REGRESSION--------\n",
            "----------------------------------\n",
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:01<00:00, 3934.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7150127226463104\n",
            "Precision: 0.7217847769028871\n",
            "Recall: 0.6997455470737913\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        " for m in range (1,6):\n",
        "        \n",
        "    #IMPORT DATA\n",
        "    dataset=pd.read_csv('data.csv')\n",
        "    dataset=dataset.replace('?',np.nan)\n",
        "    dataset.to_csv('Data.csv',index=False)\n",
        "    dataset=dataset[dataset['timeframe']==m]#.drop(['timeframe'], axis = 1)\n",
        "    dataset.reset_index(inplace=True)\n",
        "    dataset.drop(['index','timeframe'],axis=1,inplace=True)\n",
        "    \n",
        "    X=dataset.iloc[:,:-1].values\n",
        "    y=dataset.iloc[:,-1].values\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    imputer = SimpleImputer(missing_values=np.nan,strategy='median')\n",
        "    imputer.fit(X[:,:])\n",
        "    X[:,:] = imputer.transform(X[:,:])\n",
        "    \n",
        "    PCA\n",
        "    X=PCA(X,32)\n",
        "    \n",
        "    #TRAIN TEST SPLIT\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
        "    \n",
        "    #IQR OUTLIER TRUNCATING\n",
        "    for i in range(0,len(X[0])):\n",
        "        low= np.quantile(X_train[:,i],0.15)\n",
        "        high= np.quantile(X_train[:,i],0.85)\n",
        "        X_train[:,i] = np.where(X_train[:,i] <low, low,X_train[:,i])\n",
        "        X_train[:,i] = np.where(X_train[:,i] >high, high,X_train[:,i])\n",
        "        X_test[:,i] = np.where(X_test[:,i] <low, low,X_test[:,i])\n",
        "        X_test[:,i] = np.where(X_test[:,i] >high, high,X_test[:,i])\n",
        "        \n",
        "    \n",
        "    #DATA OVERSAMPLING\n",
        "    smote = SMOTE()\n",
        "    #X_test_, y_test_ = X_test, y_test\n",
        "    X_test, y_test = smote.fit_resample(X_test,y_test)\n",
        "    X_train, y_train = smote.fit_resample(X_train,y_train)\n",
        "    \n",
        "    \n",
        "    #STANDARD SCALING\n",
        "    sc = StandardScaler()\n",
        "    X_train= sc.fit_transform(X_train)\n",
        "    X_test= sc.fit_transform(X_test)\n",
        "    \n",
        "    \n",
        "    #NEURAL NETWORK\n",
        "    print('XXXXXXXXXXXXX')\n",
        "    print(\"DATASET: \"+str(m))\n",
        "    print('XXXXXXXXXXXXX\\n\\n')\n",
        "    \n",
        "    print('----------------------------------')\n",
        "    print('--------NEURAL NETWORK------------')\n",
        "    print('----------------------------------')\n",
        "    print(' ')\n",
        "    \n",
        "\n",
        "    NN(X_train,y_train,X_test,y_test,X.shape[1])\n",
        "    print('\\n\\n')\n",
        "    \n",
        "   \n",
        "    \n",
        "    #LOGISTIC REGRESSION\n",
        "    print('----------------------------------')\n",
        "    print('-------LOGISTIC REGRESSION--------')\n",
        "    print('----------------------------------')\n",
        "    print(' ')\n",
        "    \n",
        "    \n",
        "    \n",
        "    lr = Logistic_Regression(X_train, y_train)\n",
        "    lr.fit()\n",
        "    pred=lr.predict(X_test)\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    print(('Test accuracy: ')+str(accuracy_score(y_test, pred)))\n",
        "    cm = confusion_matrix(y_test, pred)\n",
        "    print('Precision: '+str(cm[1][1]/(cm[1][1]+cm[0][1])))\n",
        "    print('Recall: '+str(cm[1][1]/(cm[1][1]+cm[1][0])))\n",
        "    \n",
        "    \n",
        "    \n",
        "    print('\\n\\n')\n",
        "        "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Project_Final_7.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}